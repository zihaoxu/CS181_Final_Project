{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "#from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_files():\n",
    "    d = defaultdict(list)\n",
    "\n",
    "    parent_dir = '../Data Sets/'\n",
    "\n",
    "    path_dic = {'B': 'business_s.csv', 'C':'checkin.csv', 'R':'review_s.csv'\\\n",
    "               , 'T':'tip.csv', 'U':'user.csv'}\n",
    "\n",
    "    for key in path_dic:\n",
    "        d[key] = pd.read_csv(parent_dir + path_dic[key]).drop('Unnamed: 0', 1)\n",
    "    return d\n",
    "def show():\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "    \n",
    "def clean_format(w):\n",
    "    w = w.lower().replace('.', '').replace(',', '').replace('!', '')\n",
    "    #.replace('+', '').replace('(', '').replace(')', '')\n",
    "    return w\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = read_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_star</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>address</th>\n",
       "      <th>...</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>buz_star</th>\n",
       "      <th>state</th>\n",
       "      <th>price</th>\n",
       "      <th>credit_card</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fjMXGgOr3aCxnN48kovZ_Q</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-03-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3BBCHVND9tDPNliTFoLCHA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>We recently decided to give this place another...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bCrpStRCku_gEX3Iwuv94A</td>\n",
       "      <td>5051 W Craig Rd</td>\n",
       "      <td>...</td>\n",
       "      <td>36.238959</td>\n",
       "      <td>-115.211568</td>\n",
       "      <td>Craig Road Animal Hospital</td>\n",
       "      <td>Northwest</td>\n",
       "      <td>89130</td>\n",
       "      <td>192</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool        date  funny               review_id  \\\n",
       "0  fjMXGgOr3aCxnN48kovZ_Q     0  2015-03-09    0.0  3BBCHVND9tDPNliTFoLCHA   \n",
       "\n",
       "   review_star                                               text  useful  \\\n",
       "0          5.0  We recently decided to give this place another...     0.0   \n",
       "\n",
       "                  user_id          address     ...       latitude   longitude  \\\n",
       "0  bCrpStRCku_gEX3Iwuv94A  5051 W Craig Rd     ...      36.238959 -115.211568   \n",
       "\n",
       "                         name neighborhood  postal_code  review_count  \\\n",
       "0  Craig Road Animal Hospital    Northwest        89130           192   \n",
       "\n",
       "   buz_star state price credit_card  \n",
       "0       4.0    NV   NaN         NaN  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['RB'] = d['R'].merge(d['B'], on = 'business_id', how = 'inner')\n",
    "d['RB'] = d['RB'].dropna(subset = ['is_open'])\n",
    "d['RB'].rename(columns = {'stars_x' : 'review_star', 'stars_y':'buz_star'}, inplace = True)\n",
    "d['RB'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business_id', 'cool', 'date', 'funny', 'review_id', 'review_star', 'text', 'useful', 'user_id', 'address', 'attributes', 'categories', 'city', 'hours', 'is_open', 'latitude', 'longitude', 'name', 'neighborhood', 'postal_code', 'review_count', 'buz_star', 'state', 'price', 'credit_card']\n"
     ]
    }
   ],
   "source": [
    "print(list(d['RB']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zihaoxu/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Define pos as 4 or above, drop 3 star reviews\n",
    "df = d['RB']\n",
    "df = df[df['review_star'] != 3]\n",
    "df['pos'] = np.where(df['review_star'] >= 4, 1, 0)\n",
    "df.index = range(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive rate:  0.7429245283018868\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive rate: \", np.mean(df['pos']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zihaoxu/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# Stem all the words in reviews\n",
    "ps = PorterStemmer()\n",
    "df['text'] = [' '.join([ps.stem(w) for w in df['text'][i].split()]) for i in range(len(df['text']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['pos'], train_size = 3000/3816, random_state = 47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First review:  I find there are veri few establish that do what I would realli call 'good business' still left in the world. I'm sure there are plenti I just run in to them everi onc in a rare while. The Keg is one of them. Two stories: The first time I went here my friend and I just want a good steak so we search out yelp and found The Keg wa close. Right off the bat I notic the atmospher wa pretti nice, noth over the top, but enjoyable. I also notic that the wait staff knew their shit. Our waitress explain all the special and recommend her favorit without hesitation. The real highlight wa befor our food came when the manag came over and ask us if it wa our first time. He then brought us a shrimp cocktail on the hous to kick off our meal. The second visit wa for a friend' birthday. We order a round of chocol cake shot and the manag show up to mix them himself and bought us our first round. He also gave us each recip to take home with us. The food on both occas wa great, I haven't had a good cut of meat like it sinc I left the midwest. The wait staff is friendli and attentive, and I will definit be go back.\n",
      "\n",
      "Shape of X_train:  (3000,)\n",
      "Shape of X_test:  (816,)\n"
     ]
    }
   ],
   "source": [
    "print(\"First review: \", X_train[X_train.index[1]])\n",
    "print()\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00', 'bundt', 'domest', 'helen', 'middl', 'pumps', 'stepchild', 'worthi']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer().fit(X_train)\n",
    "vect.get_feature_names()[::2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features:  14187\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of features: \", len(vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3000x14187 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 218054 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we vectorize the X_train data\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try using a logistic regression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[156  64]\n",
      " [ 26 570]]\n",
      "Test accuracy:  0.889705882353\n",
      "AUC:  0.832733374009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "\n",
    "pred = clf.predict(vect.transform(X_test))\n",
    "\n",
    "print(confusion_matrix(y_true = y_test, y_pred = pred))\n",
    "print(\"Test accuracy: \", (confusion_matrix(y_true = y_test, y_pred = pred)[0][0] + confusion_matrix(y_true = y_test, y_pred = pred)[1][1])/len(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs: \n",
      "['lack' 'worst' 'terrible' 'ok' 'money' 'poor' 'okay' 'rude' 'won' 'wouldn'\n",
      " 'bland' 'horribl' 'gone' 'disappointed' 'not']\n",
      "\n",
      "Biggest Coefs: \n",
      "['great' 'definit' 'best' 'love' 'amazing' 'delicious' 'everyth'\n",
      " 'recommend' 'awesome' 'fresh' 'alway' 'thank' 'excel' 'amaz' 'delici']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sored_coef_index = clf.coef_[0].argsort()\n",
    "print(\"Smallest Coefs: \\n{}\\n\".format(feature_names[sored_coef_index[:15]]))\n",
    "print(\"Biggest Coefs: \\n{}\\n\".format(feature_names[sored_coef_index[:-16:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tfâ€“idf, or Term frequency-inverse document frequency, allows us to weight terms based on how important they are to a document. High weight is given to terms that appear often in a particular document, but don't appear often in the corpus. Features with low tfâ€“idf are either commonly used across all documents or rarely used and only occur in long documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7324"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect = TfidfVectorizer(min_df = 2).fit(X_train)\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[156  64]\n",
      " [ 19 577]]\n",
      "Test accuracy:  0.898284313725\n",
      "AUC:  0.83860585723\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "pred = clf.predict(vect.transform(X_test))\n",
    "\n",
    "print(confusion_matrix(y_true = y_test, y_pred = pred))\n",
    "print(\"Test accuracy: \", (confusion_matrix(y_true = y_test, y_pred = pred)[0][0] + confusion_matrix(y_true = y_test, y_pred = pred)[1][1])/len(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs: \n",
      "['not' 'lack' 'worst' 'ok' 'okay' 'no' 'poor' 'rude' 'wouldn' 'told'\n",
      " 'order' 'money' 'terrible' 'bland' 'horribl' 'won' 'custom' '20' 'paid'\n",
      " 'left' 'horrible' 'noth' 'disappoint' 'water' 'frozen']\n",
      "\n",
      "Biggest Coefs: \n",
      "['great' 'best' 'love' 'definit' 'alway' 'everyth' 'recommend' 'good'\n",
      " 'amazing' 'thank' 'awesome' 'fresh' 'delicious' 'amaz' 'excel' 'pretti'\n",
      " 'easi' 'delici' 'friendly' 'awesom' 'vegas' 'seat' 'is' 'sweet' 'happi']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sored_coef_index = clf.coef_[0].argsort()\n",
    "print(\"Smallest Coefs: \\n{}\\n\".format(feature_names[sored_coef_index[:25]]))\n",
    "print(\"Biggest Coefs: \\n{}\\n\".format(feature_names[sored_coef_index[:-26:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "# The issue with n-grams: do not, not recommend, not good\n",
    "print(clf.predict(vect.transform(['do not recommend this place',\n",
    "                                 'this place is not good'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39926"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer(min_df = 2, ngram_range = (1,2)).fit(X_train)\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[154  66]\n",
      " [ 11 585]]\n",
      "Test accuracy:  0.905637254902\n",
      "AUC:  0.840771812081\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "pred = clf.predict(vect.transform(X_test))\n",
    "\n",
    "print(confusion_matrix(y_true = y_test, y_pred = pred))\n",
    "print(\"Test accuracy: \", (confusion_matrix(y_true = y_test, y_pred = pred)[0][0] + confusion_matrix(y_true = y_test, y_pred = pred)[1][1])/len(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs: \n",
      "['not' 'no' 'order' 'worst' 'rude' 'poor' 'lack' 'told' 'ok' 'custom' 'bad'\n",
      " 'won' 'wouldn' 'okay' 'noth' 'water' 'the worst' 'horribl' 'horrible'\n",
      " 'better' 'left' 'terrible' 'tri to' 'money' 'bland']\n",
      "\n",
      "Biggest Coefs: \n",
      "['great' 'love' 'definit' 'the best' 'alway' 'best' 'good' 'and' 'amazing'\n",
      " 'everyth' 'recommend' 'amaz' 'delicious' 'thank' 'you' 'awesome' 'is'\n",
      " 'fresh' 'delici' 'awesom' 'excel' 'pretti' 'littl' 'easi' 'perfect']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sored_coef_index = clf.coef_[0].argsort()\n",
    "print(\"Smallest Coefs: \\n{}\\n\".format(feature_names[sored_coef_index[:25]]))\n",
    "print(\"Biggest Coefs: \\n{}\\n\".format(feature_names[sored_coef_index[:-26:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "# NO MORE issue with n-grams: do not, not recommend, not good\n",
    "print(clf.predict(vect.transform(['do not recommend this place',\n",
    "                                 'this place is not good'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying the voting clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression accuracy:  0.897058823529\n",
      "[[178  42]\n",
      " [ 42 554]]\n",
      "AUC:  0.869310555217\n",
      "LinearSVC accuracy:  0.906862745098\n",
      "[[169  51]\n",
      " [ 25 571]]\n",
      "AUC:  0.863117754728\n",
      "SGDClassifier accuracy:  0.901960784314\n",
      "[[174  46]\n",
      " [ 34 562]]\n",
      "AUC:  0.866931055522\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(4747)\n",
    "# LogisticRegression\n",
    "clf_LogisticRegression = LogisticRegression(class_weight = 'balanced')\n",
    "clf_LogisticRegression.fit(X_train_vectorized, y_train)\n",
    "\n",
    "pred = clf_LogisticRegression.predict(vect.transform(X_test))\n",
    "print(\"LogisticRegression accuracy: \", (confusion_matrix(y_true = y_test, y_pred = pred)[0][0] + confusion_matrix(y_true = y_test, y_pred = pred)[1][1])/len(X_test))\n",
    "print(confusion_matrix(y_true = y_test, y_pred = pred))\n",
    "print('AUC: ', roc_auc_score(y_test, pred))\n",
    "\n",
    "# LinearSVC\n",
    "clf_LinearSVC = LinearSVC(class_weight = 'balanced')\n",
    "clf_LinearSVC.fit(X_train_vectorized, y_train)\n",
    "\n",
    "pred = clf_LinearSVC.predict(vect.transform(X_test))\n",
    "print(\"LinearSVC accuracy: \", (confusion_matrix(y_true = y_test, y_pred = pred)[0][0] + confusion_matrix(y_true = y_test, y_pred = pred)[1][1])/len(X_test))\n",
    "print(confusion_matrix(y_true = y_test, y_pred = pred))\n",
    "print('AUC: ', roc_auc_score(y_test, pred))\n",
    "\n",
    "# SGDClassifier\n",
    "clf_SGDClassifier = SGDClassifier(class_weight = 'balanced')\n",
    "clf_SGDClassifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "pred = clf_SGDClassifier.predict(vect.transform(X_test))\n",
    "print(\"SGDClassifier accuracy: \", (confusion_matrix(y_true = y_test, y_pred = pred)[0][0] + confusion_matrix(y_true = y_test, y_pred = pred)[1][1])/len(X_test))\n",
    "print(confusion_matrix(y_true = y_test, y_pred = pred))\n",
    "print('AUC: ', roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying out the voted clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voted_classifier accuracy:  0.908088235294\n"
     ]
    }
   ],
   "source": [
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def predict(self, features):\n",
    "        pred_list = []\n",
    "        for c in self._classifiers:\n",
    "            pred_list.append(c.predict(features))\n",
    "        \n",
    "        res = []\n",
    "        for i in range(len(pred_list[0])):\n",
    "            a = pred_list[0][i]\n",
    "            b = pred_list[1][i]\n",
    "            c = pred_list[2][i]\n",
    "            if (a+b+c)< 2:\n",
    "                res.append(0)\n",
    "            else:\n",
    "                res.append(1)\n",
    "        return res\n",
    "\n",
    "    def confidence(self, features):\n",
    "        pred_list = []\n",
    "        for c in self._classifiers:\n",
    "            pred_list.append(c.predict(features))\n",
    "        \n",
    "        votes = pred_list[0][0] + pred_list[1][0] + pred_list[2][0]\n",
    "        if votes< 2:\n",
    "            return 1-votes/3\n",
    "        else:\n",
    "            return votes/3\n",
    "    \n",
    "voted_classifier = VoteClassifier(clf_LogisticRegression,\n",
    "                                  clf_LinearSVC, \n",
    "                                  clf_SGDClassifier) \n",
    "\n",
    "pred = voted_classifier.predict(vect.transform(X_test))\n",
    "print(\"voted_classifier accuracy: \", (confusion_matrix(y_true = y_test, y_pred = pred)[0][0] + confusion_matrix(y_true = y_test, y_pred = pred)[1][1])/len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voted_classifier.predict(vect.transform(['do not recommend this place',\n",
    "                                 'this place is not good']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0], 1.0)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentiment(text):\n",
    "    return (voted_classifier.predict(vect.transform(text)), voted_classifier.confidence(vect.transform(text)))\n",
    "\n",
    "sentiment(['I do not recommend this place'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1], 1.0)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment([\"It's sad that we cannot come back again. We liked here.\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
