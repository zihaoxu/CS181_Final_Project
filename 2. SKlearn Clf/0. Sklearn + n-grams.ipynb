{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zihaoxu/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parent_dir = '../Data Sets/'\n",
    "path_dic = {'B': 'business_s.csv', 'R':'review_text.csv', 'U':'user.csv', 'I':'review_info.csv'}\n",
    "\n",
    "def read_files():\n",
    "    d = defaultdict(list)\n",
    "    for key in path_dic:\n",
    "        d[key] = pd.read_csv(parent_dir + path_dic[key]).drop('Unnamed: 0', 1)\n",
    "    return d\n",
    "def show():\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "    \n",
    "def clean_format(w):\n",
    "    w = w.lower().replace('.', '').replace(',', '').replace('!', '')\n",
    "    return w\n",
    "d = read_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business_s.csv :  (102497, 25)\n",
      "review_text.csv :  (4736897, 2)\n",
      "user.csv :  (968039, 17)\n",
      "review_info.csv :  (4736897, 10)\n"
     ]
    }
   ],
   "source": [
    "for key in d:\n",
    "    print(path_dic[key] + ' : ', d[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4736897, 2)\n",
      "(4736897, 4)\n"
     ]
    }
   ],
   "source": [
    "print(d['R'].shape)\n",
    "d['R'] = d['R'].merge(d['I'][['review_id', 'business_id', 'review_stars']], on = 'review_id', how = 'inner')\n",
    "print(d['R'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4265614, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_stem</th>\n",
       "      <th>review_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>address</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>hours</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>buz_name</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>state</th>\n",
       "      <th>price</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>buz_review_count</th>\n",
       "      <th>buz_cool_mean</th>\n",
       "      <th>buz_funny_mean</th>\n",
       "      <th>buz_useful_mean</th>\n",
       "      <th>buz_star_mean</th>\n",
       "      <th>buz_star_std</th>\n",
       "      <th>buz_polarity_mean</th>\n",
       "      <th>buz_polarity_std</th>\n",
       "      <th>buz_subjectivity_mean</th>\n",
       "      <th>buz_subjectivity_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>thi place is horribl , we were so excit to tri...</td>\n",
       "      <td>ByRzJ8rF2KJWLr-cUNU6EA</td>\n",
       "      <td>jQsNFOzDpxPmOurSWCg1vQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14155 W Bell Rd, Ste 113</td>\n",
       "      <td>{'OutdoorSeating': True, 'WiFi': 'no', 'Restau...</td>\n",
       "      <td>['Fast Food', 'Gluten-Free', 'Asian Fusion', '...</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>{'Sunday': '10:30-21:00', 'Wednesday': '10:30-...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.638228</td>\n",
       "      <td>-112.365259</td>\n",
       "      <td>Pei Wei</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85374</td>\n",
       "      <td>AZ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.336957</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>3.26087</td>\n",
       "      <td>1.443969</td>\n",
       "      <td>0.164035</td>\n",
       "      <td>0.198044</td>\n",
       "      <td>0.53314</td>\n",
       "      <td>0.167233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_stem               review_id  \\\n",
       "16  thi place is horribl , we were so excit to tri...  ByRzJ8rF2KJWLr-cUNU6EA   \n",
       "\n",
       "               business_id  review_stars                   address  \\\n",
       "16  jQsNFOzDpxPmOurSWCg1vQ           1.0  14155 W Bell Rd, Ste 113   \n",
       "\n",
       "                                           attributes  \\\n",
       "16  {'OutdoorSeating': True, 'WiFi': 'no', 'Restau...   \n",
       "\n",
       "                                           categories      city  \\\n",
       "16  ['Fast Food', 'Gluten-Free', 'Asian Fusion', '...  Surprise   \n",
       "\n",
       "                                                hours  is_open   latitude  \\\n",
       "16  {'Sunday': '10:30-21:00', 'Wednesday': '10:30-...      1.0  33.638228   \n",
       "\n",
       "     longitude buz_name neighborhood postal_code state  price credit_card  \\\n",
       "16 -112.365259  Pei Wei          NaN       85374    AZ    2.0        True   \n",
       "\n",
       "    buz_review_count  buz_cool_mean  buz_funny_mean  buz_useful_mean  \\\n",
       "16              92.0       0.336957        0.271739          0.73913   \n",
       "\n",
       "    buz_star_mean  buz_star_std  buz_polarity_mean  buz_polarity_std  \\\n",
       "16        3.26087      1.443969           0.164035          0.198044   \n",
       "\n",
       "    buz_subjectivity_mean  buz_subjectivity_std  \n",
       "16                0.53314              0.167233  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_columns', 100)\n",
    "d['RB'] = d['R'].merge(d['B'], on = 'business_id', how = 'left')\n",
    "d['RB'] = d['RB'].dropna(subset = ['is_open'])\n",
    "print(d['RB'].shape)\n",
    "d['RB'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4265614, 28)\n",
      "['text_stem', 'review_id', 'business_id', 'review_stars', 'address', 'attributes', 'categories', 'city', 'hours', 'is_open', 'latitude', 'longitude', 'buz_name', 'neighborhood', 'postal_code', 'state', 'price', 'credit_card', 'buz_review_count', 'buz_cool_mean', 'buz_funny_mean', 'buz_useful_mean', 'buz_star_mean', 'buz_star_std', 'buz_polarity_mean', 'buz_polarity_std', 'buz_subjectivity_mean', 'buz_subjectivity_std']\n"
     ]
    }
   ],
   "source": [
    "print(d['RB'].shape)\n",
    "print(list(d['RB']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define pos as 4 or above, drop 3 star reviews\n",
    "np.random.seed(47)\n",
    "df = d['RB'][['text_stem', 'review_stars']]\n",
    "df = df.sample(frac = 0.05, replace = False)\n",
    "df = df[df['review_stars'] != 3]\n",
    "df['pos'] = np.where(df['review_stars'] >= 4, 1, 0)\n",
    "df = df.drop('review_stars', 1)\n",
    "df.index = range(len(df))\n",
    "\n",
    "d = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(187890, 2)\n",
      "Positive rate:  0.7482463143328544\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(\"Positive rate: \", np.mean(df['pos']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed: \n",
      "the restaur is kinda hidden in the plaza on dobson and guadalup . the place is small but clean . servic wa good and we did n't have to wait to long for the food . We order some gogi , spici chicken , tofu soup and some korean street taco . everyth tast delici and the portion were gener . I highli recommend the korean street taco !\n"
     ]
    }
   ],
   "source": [
    "print(\"Stemmed: \")\n",
    "print(df['text_stem'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(\"before the merge: \", df.shape)\n",
    "\n",
    "# merged = df.merge(d['U'], on = 'user_id', how = 'left')\n",
    "# print(\"after the merge: \", merged.shape)\n",
    "# merged.dropna(subset = ['review_text'])\n",
    "# print(\"after the merge: \", merged.shape)\n",
    "\n",
    "# pd.set_option('display.max_columns', 100)\n",
    "# merged.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (140917,)\n",
      "Shape of X_test:  (46973,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text_stem'], df['pos'], train_size = .75, random_state = 47)\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " 'aroma',\n",
       " 'burlesque',\n",
       " 'cosmo',\n",
       " 'effortless',\n",
       " 'gaurante',\n",
       " 'imperfect',\n",
       " 'loaner',\n",
       " 'navigate',\n",
       " 'pizooki',\n",
       " 'robl',\n",
       " 'somon',\n",
       " 'tomi',\n",
       " 'whittl']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(max_df = 0.95, min_df = 3, stop_words = 'english').fit(X_train)\n",
    "vect.get_feature_names()[::2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features:  20067\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of features: \", len(vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<140917x20067 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6082079 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we vectorize the X_train data\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10080  1745]\n",
      " [ 1519 33629]]\n",
      "Test accuracy:  0.930513273583\n",
      "AUC:  0.90460701844\n"
     ]
    }
   ],
   "source": [
    "# Try using a logistic regression\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "pred = clf.predict(vect.transform(X_test))\n",
    "\n",
    "print(confusion_matrix(y_true = y_test, y_pred = pred))\n",
    "print(\"Test accuracy: \", (confusion_matrix(y_true = y_test, y_pred = pred)[0][0] + confusion_matrix(y_true = y_test, y_pred = pred)[1][1])/len(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs: \n",
      "['slowest' 'loo' 'mehh' 'hoity' 'canon' 'keyword' 'eerili' 'pail'\n",
      " 'horrible' 'placat' 'drafti' 'symposium' 'calorie' 'wp' 'downhil']\n",
      "\n",
      "Biggest Coefs: \n",
      "['restauranteur' 'hart' 'wac' 'kat' 'unobtrus' 'caress' 'chrysanthemum'\n",
      " 'recheck' 'loungi' 'crackl' 'josi' '33rd' 'erica' 'lebanon' 'ralphi']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sored_coef_index = clf.coef_[0].argsort()\n",
    "print(\"Smallest Coefs: \\n{}\\n\".format(feature_names[sored_coef_index[:15]]))\n",
    "print(\"Biggest Coefs: \\n{}\\n\".format(feature_names[sored_coef_index[:-16:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf–idf, or Term frequency-inverse document frequency, allows us to weight terms based on how important they are to a document. High weight is given to terms that appear often in a particular document, but don't appear often in the corpus. Features with low tf–idf are either commonly used across all documents or rarely used and only occur in long documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26755"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer(max_df = .95, min_df = 3, stop_words = 'english').fit(X_train)\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10321  1504]\n",
      " [ 1118 34030]]\n",
      "Test accuracy:  0.944180699551\n",
      "AUC:  0.920501743037\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "pred = clf.predict(vect.transform(X_test))\n",
    "\n",
    "print(confusion_matrix(y_true = y_test, y_pred = pred))\n",
    "print(\"Test accuracy: \", (confusion_matrix(y_true = y_test, y_pred = pred)[0][0] + confusion_matrix(y_true = y_test, y_pred = pred)[1][1])/len(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs: \n",
      "['worst' 'bland' 'mediocr' 'terribl' 'downhil' 'aw' 'horribl' 'meh'\n",
      " 'tasteless' 'rude' 'flavorless' 'underwhelm' 'poor' 'disgust' 'wast'\n",
      " 'poorli' 'overr' 'overpr' 'atroci' 'ined' 'lack' 'slowest' 'filthi'\n",
      " 'uninspir' 'disappoint']\n",
      "\n",
      "Biggest Coefs: \n",
      "['delici' 'amaz' 'great' 'excel' 'perfect' 'awesom' 'fantast' 'love'\n",
      " 'pleasantli' 'best' 'skeptic' 'perfectli' 'outstand' 'highli' 'notch'\n",
      " 'definit' 'glad' 'downsid' 'heaven' 'gem' 'erica' 'fabul' 'phenomen'\n",
      " 'genuin' 'exceed']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sored_coef_index = clf.coef_[0].argsort()\n",
    "print(\"Smallest Coefs: \\n{}\\n\".format(feature_names[sored_coef_index[:25]]))\n",
    "print(\"Biggest Coefs: \\n{}\\n\".format(feature_names[sored_coef_index[:-26:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "# The issue with n-grams: do not, not recommend, not good\n",
    "print(clf.predict(vect.transform(['do not recommend this place',\n",
    "                                 'this place is not good'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444315\n"
     ]
    }
   ],
   "source": [
    "# vect = TfidfVectorizer(max_df = .95, min_df = 3, ngram_range = (1,2)).fit(X_train)\n",
    "vect = TfidfVectorizer(max_df = .95, min_df = 3, ngram_range = (1,2)).fit(X_train)\n",
    "print(len(vect.get_feature_names()))\n",
    "\n",
    "# save_classifier = open(\"pickled_algos/vect.pickle\",\"wb\")\n",
    "# pickle.dump(vect, save_classifier)\n",
    "# save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10820  1005]\n",
      " [  661 34487]]\n",
      "Test accuracy:  0.964532816725\n",
      "AUC:  0.94810218993\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "pred = clf.predict(vect.transform(X_test))\n",
    "\n",
    "print(confusion_matrix(y_true = y_test, y_pred = pred))\n",
    "print(\"Test accuracy: \", (confusion_matrix(y_true = y_test, y_pred = pred)[0][0] + confusion_matrix(y_true = y_test, y_pred = pred)[1][1])/len(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs: \n",
      "['worst' 'two star' 'not' 'disappoint' 'not worth' 'bland' 'terribl'\n",
      " 'horribl' 'mediocr' 'veri disappoint' 'rude' 'meh' 'aw' 'at best' 'overpr'\n",
      " 'poor' 'lack' 'not good' 'wors' 'not recommend' 'disgust' 'dirti' 'no'\n",
      " 'never again' 'will never' 'no thank' 'wast' 'to love' 'wo be' 'noth'\n",
      " 'not impress' 'will not' 'gross' 'poorli' 'not great' 'wo' 'unfortun'\n",
      " 'underwhelm' 'elsewher' 'unprofession' 'suck' 'not veri' 'ruin'\n",
      " 'never come' 'definit not']\n",
      "\n",
      "Biggest Coefs: \n",
      "['delici' 'great' 'amaz' 'awesom' 'excel' 'love' 'perfect' 'best'\n",
      " 'not disappoint' 'fantast' 'good' 'be disappoint' 'definit' 'you wo'\n",
      " 'highli recommend' 'outstand' 'perfectli' 'not bad' 'realli good' 'happi'\n",
      " 'wonder' 'not too' 'friendli' 'never disappoint' 'thank' 'better than'\n",
      " 'alway' 'love thi' 'my onli' 'four star' 'go wrong' 'the best'\n",
      " 'will definit' 'not onli' 'fun' 'yummi' 'easi' 'tasti' 'so good'\n",
      " 'profession' 'ca wait' 'recommend' 'fabul' 'love the' 'veri good']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sored_coef_index = clf.coef_[0].argsort()\n",
    "print(\"Smallest Coefs: \\n{}\\n\".format(feature_names[sored_coef_index[:45]]))\n",
    "print(\"Biggest Coefs: \\n{}\\n\".format(feature_names[sored_coef_index[:-46:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_words = pd.DataFrame(feature_names[sored_coef_index[:200]], columns = ['positive_words'])\n",
    "pos_words.to_csv('Positive Words.csv')\n",
    "neg_words = pd.DataFrame(feature_names[sored_coef_index[:-200:-1]], columns = ['negative_words'])\n",
    "neg_words.to_csv('Negative Words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "# NO MORE issue with n-grams: do not, not recommend, not good\n",
    "print(clf.predict(vect.transform(['do not recommend this place',\n",
    "                                 'this place is not good'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying the voting clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression accuracy:  0.954888978775\n",
      "[[11244   581]\n",
      " [ 1538 33610]]\n",
      "AUC:  0.953554491776\n",
      "LinearSVC accuracy:  0.964532816725\n",
      "[[10820  1005]\n",
      " [  661 34487]]\n",
      "AUC:  0.94810218993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zihaoxu/anaconda/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier accuracy:  0.947075979818\n",
      "[[11221   604]\n",
      " [ 1882 33266]]\n",
      "AUC:  0.947688383113\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(47)\n",
    "# LogisticRegression\n",
    "clf_LogisticRegression = LogisticRegression(class_weight = 'balanced') #class_weight = 'balanced'\n",
    "clf_LogisticRegression.fit(X_train_vectorized, y_train)\n",
    "\n",
    "pred = clf_LogisticRegression.predict(vect.transform(X_test))\n",
    "print(\"LogisticRegression accuracy: \", (confusion_matrix(y_true = y_test, y_pred = pred)[0][0] + confusion_matrix(y_true = y_test, y_pred = pred)[1][1])/len(X_test))\n",
    "print(confusion_matrix(y_true = y_test, y_pred = pred))\n",
    "print('AUC: ', roc_auc_score(y_test, pred))\n",
    "\n",
    "# LinearSVC\n",
    "clf_LinearSVC = LinearSVC() #class_weight = 'balanced'\n",
    "clf_LinearSVC.fit(X_train_vectorized, y_train)\n",
    "\n",
    "pred = clf_LinearSVC.predict(vect.transform(X_test))\n",
    "print(\"LinearSVC accuracy: \", (confusion_matrix(y_true = y_test, y_pred = pred)[0][0] + confusion_matrix(y_true = y_test, y_pred = pred)[1][1])/len(X_test))\n",
    "print(confusion_matrix(y_true = y_test, y_pred = pred))\n",
    "print('AUC: ', roc_auc_score(y_test, pred))\n",
    "\n",
    "# SGDClassifier\n",
    "clf_SGDClassifier = SGDClassifier(class_weight = 'balanced') #class_weight = 'balanced'\n",
    "clf_SGDClassifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "pred = clf_SGDClassifier.predict(vect.transform(X_test))\n",
    "print(\"SGDClassifier accuracy: \", (confusion_matrix(y_true = y_test, y_pred = pred)[0][0] + confusion_matrix(y_true = y_test, y_pred = pred)[1][1])/len(X_test))\n",
    "print(confusion_matrix(y_true = y_test, y_pred = pred))\n",
    "print('AUC: ', roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying out the voted clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voted_classifier accuracy:  0.955208311157\n"
     ]
    }
   ],
   "source": [
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def predict(self, features):\n",
    "        pred_list = []\n",
    "        for c in self._classifiers:\n",
    "            pred_list.append(c.predict(features))\n",
    "        \n",
    "        res = []\n",
    "        for i in range(len(pred_list[0])):\n",
    "            a = pred_list[0][i]\n",
    "            b = pred_list[1][i]\n",
    "            c = pred_list[2][i]\n",
    "            if (a+b+c)< 2:\n",
    "                res.append(0)\n",
    "            else:\n",
    "                res.append(1)\n",
    "        return res\n",
    "\n",
    "    def confidence(self, features):\n",
    "        pred_list = []\n",
    "        for c in self._classifiers:\n",
    "            pred_list.append(c.predict(features))\n",
    "        \n",
    "        votes = pred_list[0][0] + pred_list[1][0] + pred_list[2][0]\n",
    "        if votes< 2:\n",
    "            return 1-votes/3\n",
    "        else:\n",
    "            return votes/3\n",
    "    \n",
    "voted_classifier = VoteClassifier(clf_LogisticRegression,\n",
    "                                  clf_LinearSVC, \n",
    "                                  clf_SGDClassifier) \n",
    "\n",
    "pred = voted_classifier.predict(vect.transform(X_test))\n",
    "print(\"voted_classifier accuracy: \", (confusion_matrix(y_true = y_test, y_pred = pred)[0][0] + confusion_matrix(y_true = y_test, y_pred = pred)[1][1])/len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save_classifier = open(\"pickled_algos/clf_LogisticRegression.pickle\",\"wb\")\n",
    "# pickle.dump(clf_LogisticRegression, save_classifier)\n",
    "# save_classifier.close()\n",
    "\n",
    "# save_classifier = open(\"pickled_algos/clf_LinearSVC.pickle\",\"wb\")\n",
    "# pickle.dump(clf_LinearSVC, save_classifier)\n",
    "# save_classifier.close()\n",
    "\n",
    "# save_classifier = open(\"pickled_algos/clf_SGDClassifier.pickle\",\"wb\")\n",
    "# pickle.dump(clf_SGDClassifier, save_classifier)\n",
    "# save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voted_classifier.predict(vect.transform(['do not recommend this place',\n",
    "                                 'this place is not good']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1.0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentiment(text):\n",
    "    return (voted_classifier.predict(vect.transform(text))[0], voted_classifier.confidence(vect.transform(text)))\n",
    "\n",
    "sentiment(['I do not recommend this place'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1.0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment([\"we will come back again.\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'python', 'programmer', 'named', 'pythoner', 'is', 'pythoning', 'a', 'game', 'pythonly']\n",
      "['the', 'python', 'programmer', 'named', 'pythoner', 'is', 'pythoning', 'a', 'game', 'pythonly']\n",
      "['the', 'python', 'programmer', 'named', 'pythoner', 'pythoning', 'game', 'pythonly']\n",
      "['the', 'python', 'programm', 'name', 'python', 'python', 'game', 'pythonli']\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "example_sec = \"The python programmer named pythoner is pythoning a game pythonly\"\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = list(set(stopwords.words('english')))\n",
    "\n",
    "print([w for w in word_tokenize(example_sec)])\n",
    "print([clean_format(w) for w in word_tokenize(example_sec)])\n",
    "print([clean_format(w) for w in word_tokenize(example_sec) if w not in stopWords])\n",
    "print([ps.stem(clean_format(w)) for w in word_tokenize(example_sec) if w not in stopWords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sens = [\"The python\", \"The python programmer named pythoner \", \"The python programmer named pythoner is pythoning a game pythonly\"]\n",
    "samp_list = np.array([\" \".join([ps.stem(clean_format(w)) for w in word_tokenize(example_sec) if w not in stopWords]) for example_sec in sens])\n",
    "# samp_list\n",
    "transed = vect.transform(samp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'amaz'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('amazing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
